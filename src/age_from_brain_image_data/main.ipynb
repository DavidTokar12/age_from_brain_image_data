{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8745ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.gaussian_process.kernels as kernels\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "78ab9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = Path(\"/workspaces/age_from_brain_image_data/src/age_from_brain_image_data/data\")\n",
    "x_train = pd.read_csv(BASE_PATH / 'X_train.csv', skiprows=1, header=None).values[:, 1:]\n",
    "x_test = pd.read_csv(BASE_PATH / 'X_test.csv', skiprows=1, header=None).values[:, 1:]\n",
    "y_train = pd.read_csv(BASE_PATH / 'y_train.csv', skiprows=1, header=None).values[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a7687ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(x_train, y_train, contamination=0.047, random_state=42):\n",
    "\n",
    "    x_train_df = pd.DataFrame(x_train).copy()\n",
    "    y_train_series = pd.Series(np.asarray(y_train).flatten(), index=x_train_df.index)\n",
    "    \n",
    "    med = x_train_df.median(axis=0)\n",
    "    xtr_imp = x_train_df.fillna(med)\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    xtr_std = scaler.fit_transform(xtr_imp)\n",
    "    \n",
    "    pca = PCA(n_components=2, random_state=random_state)\n",
    "    x_proj = pca.fit_transform(xtr_std)\n",
    "    \n",
    "    \n",
    "    iso = IsolationForest(contamination=contamination, random_state=random_state)\n",
    "    mask = iso.fit_predict(x_proj) == 1\n",
    "    \n",
    "    n_outliers = np.sum(~mask)\n",
    "    print(f\"[OutlierRemoval] Removed {n_outliers} outliers\")\n",
    "    \n",
    "    if isinstance(x_train, np.ndarray):\n",
    "        return x_train[mask], y_train[mask]\n",
    "    else:\n",
    "        return x_train_df[mask], y_train_series[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "381fe6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpearmanSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select top K features by Spearman correlation with target.\"\"\"\n",
    "    \n",
    "    def __init__(self, top_k=200):\n",
    "        self.top_k = top_k\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        if y is None:\n",
    "            raise ValueError(\"SpearmanSelector requires y\")\n",
    "        \n",
    "        x_df = pd.DataFrame(x) if not isinstance(x, pd.DataFrame) else x\n",
    "        y_series = pd.Series(np.asarray(y).flatten(), index=x_df.index)\n",
    "        \n",
    "        spearman_corr = x_df.corrwith(y_series, method='spearman').abs()\n",
    "        \n",
    "        n_keep = min(self.top_k, len(spearman_corr))\n",
    "        top_features = spearman_corr.nlargest(n_keep).index\n",
    "        \n",
    "        self.selected_features_ = top_features.tolist()\n",
    "        self.n_features_in_ = x_df.shape[1]\n",
    "        \n",
    "        print(f\"[SpearmanSelector] Selected {len(self.selected_features_)} features (from {self.n_features_in_})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        x_df = pd.DataFrame(X) if not isinstance(X, pd.DataFrame) else X\n",
    "        return x_df.iloc[:, self.selected_features_].values\n",
    "\n",
    "\n",
    "class RFSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Select top K features by RandomForest feature importance.\"\"\"\n",
    "    \n",
    "    def __init__(self, top_k=200, n_estimators=1000, max_depth=None, \n",
    "                 min_samples_leaf=1, max_features='sqrt', random_state=42):\n",
    "        self.top_k = top_k\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.random_state = random_state\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        \n",
    "        if y is None:\n",
    "            raise ValueError(\"RFSelector requires y\")\n",
    "        \n",
    "        x_df = pd.DataFrame(x) if not isinstance(x, pd.DataFrame) else x\n",
    "        y_series = pd.Series(np.asarray(y).flatten())\n",
    "        \n",
    "        self.rf_ = RandomForestRegressor(\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            max_features=self.max_features,\n",
    "            random_state=self.random_state,\n",
    "            n_jobs=-1,\n",
    "            verbose=0\n",
    "        )\n",
    "        self.rf_.fit(x_df, y_series)\n",
    "        \n",
    "        importances = pd.Series(self.rf_.feature_importances_, index=x_df.columns)\n",
    "        importances = importances.sort_values(ascending=False)\n",
    "        \n",
    "        n_keep = min(self.top_k, len(importances)) if self.top_k else len(importances)\n",
    "        self.selected_features_ = importances.head(n_keep).index.tolist()\n",
    "        self.n_features_in_ = x_df.shape[1]\n",
    "        \n",
    "        print(f\"[RFSelector] Selected {len(self.selected_features_)} features (from {self.n_features_in_})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_df = pd.DataFrame(x) if not isinstance(x, pd.DataFrame) else x\n",
    "        return x_df.iloc[:, self.selected_features_].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be66f69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaNAwareScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Scaler that preserves NaN positions.\n",
    "    1. Remember NaN positions\n",
    "    2. Fill NaNs with median temporarily\n",
    "    3. Scale the data\n",
    "    4. Restore NaNs at original positions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, with_mean=True, with_std=True):\n",
    "        self.with_mean = with_mean\n",
    "        self.with_std = with_std\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        x_df = pd.DataFrame(x)\n",
    "\n",
    "        self.median_ = x_df.median(axis=0)\n",
    "\n",
    "        x_filled = x_df.fillna(self.median_)\n",
    "\n",
    "        self.scaler_ = StandardScaler(with_mean=self.with_mean, with_std=self.with_std)\n",
    "        self.scaler_.fit(x_filled)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        x_df = pd.DataFrame(x)\n",
    "\n",
    "        nan_mask = x_df.isna()\n",
    "\n",
    "        x_filled = x_df.fillna(self.median_)\n",
    "\n",
    "        x_scaled = self.scaler_.transform(x_filled)\n",
    "        x_scaled_df = pd.DataFrame(x_scaled, index=x_df.index, columns=x_df.columns)\n",
    "\n",
    "        x_scaled_df[nan_mask] = np.nan\n",
    "\n",
    "        return x_scaled_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "668ce9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_pipeline(random_state=42):\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            (\"variance\", VarianceThreshold()),\n",
    "            (\"scaler\", NaNAwareScaler()),\n",
    "            (\"knn_imputer\", KNNImputer()),\n",
    "            (\"spearman\", SpearmanSelector()),\n",
    "            (\"rf_selector\", RFSelector(random_state=random_state)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "98862227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(random_state=42):\n",
    "    \n",
    "    kernel = kernels.ConstantKernel(1.0, (1e-3, 1e3)) \\\n",
    "        * kernels.RationalQuadratic(length_scale=1.0, alpha=1.0) \\\n",
    "        + kernels.WhiteKernel(noise_level=1e-3, noise_level_bounds=(1e-6, 1e1))\n",
    "    \n",
    "    gpr = GaussianProcessRegressor(\n",
    "        kernel=kernel,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    model = StackingRegressor(\n",
    "        estimators=[\n",
    "            (\"svr\", NuSVR()),\n",
    "            (\"hgb\", HistGradientBoostingRegressor(random_state=random_state)),\n",
    "            (\"gp\", gpr)\n",
    "        ],\n",
    "        final_estimator=LinearRegression()\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7484d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OutlierRemoval] Removed 57 outliers\n"
     ]
    }
   ],
   "source": [
    "x_train_clean, y_train_clean = remove_outliers(\n",
    "    x_train, y_train, contamination=0.047, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23aeb7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "[SpearmanSelector] Selected 202 features (from 828)\n",
      "[SpearmanSelector] Selected 202 features (from 828)\n",
      "[SpearmanSelector] Selected 202 features (from 828)\n",
      "[RFSelector] Selected 173 features (from 202)\n",
      "[RFSelector] Selected 173 features (from 202)\n",
      "[RFSelector] Selected 173 features (from 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SpearmanSelector] Selected 202 features (from 828)\n",
      "[RFSelector] Selected 173 features (from 202)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/workspaces/age_from_brain_image_data/.venv/lib/python3.12/site-packages/sklearn/gaussian_process/kernels.py:440: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-06. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test predictions: shape=(776,), mean=69.88\n"
     ]
    }
   ],
   "source": [
    "feature_pipeline = build_feature_pipeline()\n",
    "model = build_model()\n",
    "\n",
    "full_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"features\", feature_pipeline),\n",
    "        (\"model\", model),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"features__variance__threshold\": [1e-7],\n",
    "    \"features__scaler__with_mean\": [True],\n",
    "    \"features__scaler__with_std\": [True],\n",
    "    \"features__knn_imputer__n_neighbors\": [1],\n",
    "    \"features__knn_imputer__weights\": [\"distance\"],\n",
    "    \"features__spearman__top_k\": [202],\n",
    "    \"features__rf_selector__top_k\": [173],\n",
    "    \"features__rf_selector__n_estimators\": [1000],\n",
    "    \"features__rf_selector__max_depth\": [None],\n",
    "    \"features__rf_selector__min_samples_leaf\": [1],\n",
    "    \"features__rf_selector__max_features\": [\"sqrt\"],\n",
    "\n",
    "    # Model params - NuSVR\n",
    "    \"model__svr__C\": [55],\n",
    "    \"model__svr__gamma\": [\"scale\"],\n",
    "    \"model__svr__nu\": [0.5],\n",
    "    \"model__svr__kernel\": [\"rbf\"],\n",
    "    \n",
    "    # Model params - HistGradientBoosting\n",
    "    \"model__hgb__learning_rate\": [0.1],\n",
    "    \"model__hgb__max_iter\": [100],\n",
    "    \"model__hgb__max_depth\": [None],\n",
    "    \"model__hgb__min_samples_leaf\": [20],\n",
    "    \n",
    "    # Model params - GaussianProcess\n",
    "    \"model__gp__alpha\": [0.0],\n",
    "    \"model__gp__normalize_y\": [True],\n",
    "    \"model__gp__n_restarts_optimizer\": [8],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    full_pipeline,\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=3,\n",
    ")\n",
    "\n",
    "grid.fit(x_train_clean, y_train_clean)\n",
    "\n",
    "y_test_pred = grid.predict(x_test)\n",
    "print(f\"\\nTest predictions: shape={y_test_pred.shape}, mean={y_test_pred.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca259744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Score (neg MSE): -26.5114\n",
      "Best RMSE: 5.1489\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best CV Score: {grid.best_score_:.4f}\")\n",
    "print(f\"Best RMSE: {np.sqrt(-grid.best_score_):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdc65f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
